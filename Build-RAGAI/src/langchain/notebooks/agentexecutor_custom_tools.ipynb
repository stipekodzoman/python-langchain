{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Search Tools for Retrieval Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq langchain langchainhub huggingface_hub transformers jinja2 numexpr langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [@tool decorator](https://python.langchain.com/docs/modules/agents/tools/custom_tools \"Learn more\")\n",
    "\n",
    "The `@tool` decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function's docstring as the tool's description - so a **docstring** ***MUST*** be provided.\n",
    "\n",
    "Ex.\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "```\n",
    "\n",
    "We can access the tool's properties directly\n",
    "```python\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "```\n",
    "\n",
    "```shell\n",
    "multiply\n",
    "multiply(a: int, b: int) -> int - Multiply two numbers.\n",
    "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
    "```\n",
    "\n",
    "Later we'll be able to observe the difference in output format depending on whether we call our functions with the `@tool` decorator as regular functions, or as tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, BaseTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "If you have access to LangSmith, it will be extremely helpful as projects become increasingly more complex because it allows the tracing of action steps made throughout execution. \n",
    "\n",
    "This is especially true for us since we're building custom tools, creating an agent using Hugging Face's Model Hub, and tying everything together inside a runnable chain.\n",
    "\n",
    "It becomes even more true as you add memory, vectorstore searching and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"build-custom-tools\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Arxiv Search](https://python.langchain.com/docs/integrations/tools/arxiv \"Learn more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"arxiv_search\")\n",
    "def arxiv_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This function uses the ArxivAPIWrapper to search for scientific papers on Arxiv.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The search term to use in the query.\n",
    "\n",
    "    Returns:\n",
    "    str: The search results from Arxiv.\n",
    "    \"\"\"\n",
    "    # Create an instance of the ArxivAPIWrapper\n",
    "    arxiv = ArxivAPIWrapper()\n",
    "\n",
    "    # Perform the search query\n",
    "    results = arxiv.run(query)\n",
    "\n",
    "    # Return the search results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published: 2023-06-21\n",
      "Title: TauPETGen: Text-Conditional Tau PET Image Synthesis Based on Latent Diffusion Models\n",
      "Authors: Se-In Jang, Cristina Lois, Emma Thibault, J. Alex Becker, Yafei Dong, Marc D. Normandin, Julie C. Price, Keith A. Johnson, Georges El Fakhri, Kuang Gong\n",
      "Summary: In this work, we developed a novel text-guided image synthesis technique\n",
      "which could generate realistic tau PET images from textual descriptions and the\n",
      "subject's MR image. The generated tau PET images have the potential to be used\n",
      "in examining relations between different measures and also increasing the\n",
      "public availability of tau PET datasets. The method was based on latent\n",
      "diffusion models. Both textual descriptions and the subject's MR prior image\n",
      "were utilized as conditions during image generation. The subject's MR image can\n",
      "provide anatomical details, while the text descriptions, such as gender, scan\n",
      "time, cognitive test scores, and amyloid status, can provide further guidance\n",
      "regarding where the tau neurofibrillary tangles might be deposited. Preliminary\n",
      "experimental results based on clinical [18F]MK-6240 datasets demonstrate the\n",
      "feasibility of the proposed method in generating realistic tau PET images at\n",
      "different clinical stages.\n"
     ]
    }
   ],
   "source": [
    "print(arxiv_search(\"2306.11984\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_search \n",
      "\n",
      " arxiv_search(query: str) -> str - This function uses the ArxivAPIWrapper to search for scientific papers on Arxiv.\n",
      "\n",
      "    Parameters:\n",
      "    query (str): The search term to use in the query.\n",
      "\n",
      "    Returns:\n",
      "    str: The search results from Arxiv. \n",
      "\n",
      " {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        arxiv_search.name,\n",
    "        \"\\n\\n\",\n",
    "        arxiv_search.description,\n",
    "        \"\\n\\n\",\n",
    "        arxiv_search.args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2023-06-21\\nTitle: TauPETGen: Text-Conditional Tau PET Image Synthesis Based on Latent Diffusion Models\\nAuthors: Se-In Jang, Cristina Lois, Emma Thibault, J. Alex Becker, Yafei Dong, Marc D. Normandin, Julie C. Price, Keith A. Johnson, Georges El Fakhri, Kuang Gong\\nSummary: In this work, we developed a novel text-guided image synthesis technique\\nwhich could generate realistic tau PET images from textual descriptions and the\\nsubject's MR image. The generated tau PET images have the potential to be used\\nin examining relations between different measures and also increasing the\\npublic availability of tau PET datasets. The method was based on latent\\ndiffusion models. Both textual descriptions and the subject's MR prior image\\nwere utilized as conditions during image generation. The subject's MR image can\\nprovide anatomical details, while the text descriptions, such as gender, scan\\ntime, cognitive test scores, and amyloid status, can provide further guidance\\nregarding where the tau neurofibrillary tangles might be deposited. Preliminary\\nexperimental results based on clinical [18F]MK-6240 datasets demonstrate the\\nfeasibility of the proposed method in generating realistic tau PET images at\\ndifferent clinical stages.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function as a tool\n",
    "arxiv_search.run(\"2306.11984\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Google Jobs](https://python.langchain.com/docs/integrations/tools/google_jobs \"Learn more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq google-search-results\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.google_jobs import GoogleJobsQueryRun\n",
    "from langchain.utilities.google_jobs import GoogleJobsAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"google_job_search\")\n",
    "def google_job_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This function uses the GoogleJobsAPIWrapper to search for jobs on Google Jobs.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The search term to use in the query.\n",
    "\n",
    "    Returns:\n",
    "    str: The search results from Google Jobs.\n",
    "    \"\"\"\n",
    "    # create an instance of the GoogleJobsQueryRun\n",
    "    gjs = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper())\n",
    "\n",
    "    # Perform the search query\n",
    "    results = gjs.run(query)\n",
    "\n",
    "    # return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________________________\n",
      "Job Title: (USA) Software Engineer II\n",
      "Company Name: Walmart\n",
      "Location:   Bentonville, AR   \n",
      "Description: Position Summary...\n",
      "\n",
      "What you'll do...\n",
      "\n",
      "What you'll do...\n",
      "\n",
      "It’s exciting time to join our Walmart journey. We are seeking a Software Engineer III to support the Finance Technology.  \n",
      "\n",
      "About the Team\n",
      "\n",
      "As a part of Walmart Finance Technology – Finance Data Factory (FDF), we build industry defining Data platform/workflows that process large quality of general ledger data and applications that run on data platform for visualization also, Machine Learning and statistical modeling that enable transparency, governance, and automation. The goals include improved Business partner user experience; standardizing the core and utilizing reporting/predictive analytics to uncover insights faster.\n",
      "\n",
      "You will be in the unique position to be of service to associates as a member of this organization supporting all segments of Walmart Finance. If you are the type of person who feels a personal stake in everything that you work on, has a strong sense of ownership, has a love for financial data, enjoys solving complex problems, has a passion for privacy, knows how to foster strong relationships and build trust, and works for the success of the product - then this role could be for you. The ideal candidate will be a driver for any given workstream within the program, working closely with the engineering and business teams to take an idea thru implementation and stabilization.\n",
      "\n",
      "Also, you will be positioned to work on building re-usable frameworks for centralized data flow monitoring & Data Quality like impact-based alerting, orchestrate with multiple systems in the landscape to provide end-to-end visibility and connectivity between the systems to achieve a business goal. Identifies data gaps upfront. Provides visibility into data correctness, completeness, accuracy for downstream systems. Enabling data transparency, insights hence help kick off the data remediation process in upstream systems.\n",
      "\n",
      "You’ll really wow us if…\n",
      "• You are a driver, takes responsibility to ensure timely delivery.\n",
      "• You are passionate, driven and humble in your approach.\n",
      "• You’re excited about solving challenges.\n",
      "• You’re team-centric in spirit and in execution.\n",
      "• You’re leading and participating in medium- to large-scale, complex, cross-functional projects by reviewing project requirements, translating requirements into technical solutions, gathering requested information (for example, design documents, product requirements, wire frames).\n",
      "• You’re writing and developing code; conducting unit testing, communicating status and issues to team members and stakeholders, collaborating with project team and cross functional teams.\n",
      "\n",
      "You’ll make an impact by…\n",
      "• Effectively translating requirements into project parameters while working with agility.\n",
      "• Helping cross-functional teams to solve for business problems and develop solutions that enable us to redefine a “best-in-class” customer experience.\n",
      "• Encouraging the project teams that you oversee to work collaboratively and to aim for insight-driven outcomes.\n",
      "\n",
      "Responsibilities & Qualifications…\n",
      "• Experience in Technical Solutions Architecture and design leadership.\n",
      "• Experience using Javascript, HTML/CSS, ReactJs or next.js\n",
      "• Strong Java, Spring framework, Kafka, SQL and cloud experience such as Azure.\n",
      "• Strong experience in RESTful Microservices\n",
      "• Container technologies such as Docker on Kubernetes\n",
      "• Strong API design, development, and management\n",
      "• Experience with cloud native technology, CI/CD (KITT)\n",
      "• Experience with third-party libraries and APIs\n",
      "• Clear Communication, including the ability to create functional charts.\n",
      "• Ability to multitask between several different requirements and features concurrently.\n",
      "• Superior analytical skills with a good problem-solving attitude.\n",
      "• Ability to perform in a team environment.\n",
      "• Being an independent thinker and problem solver\n",
      "• Being able to understand UI tech stack, needs and limitations.\n",
      "• Strong sense of urgency\n",
      "\n",
      "Experience\n",
      "• 3 to 4 years of software development experience\n",
      "• Professional frontend development experience using Javascript, HTML/CSS, ReactJs or next.js\n",
      "• Strong experience with UI tech stack using React JS, React native\n",
      "• Experience with UI testing frameworks like Jest\n",
      "• Software development (Java or Python, Pysprak is preferable)\n",
      "• Solid skills in java stack (Spring, Maven, Hibernate)\n",
      "• Solid experience with REST APIs\n",
      "• Strong experience within the Cloud Services using Azure or Google GCP\n",
      "• Experience with Spark Engine (Databrick or DataProc)\n",
      "• Experience working with building Data Engineering Pipelines\n",
      "• Experience using source control systems (git)\n",
      "• Experience with working with CI/CD (Jenkins/Travis)\n",
      "• Experience with working with cloud deployments (scaling, resiliency, load balancing etc)\n",
      "• Experience with SQL and NoSQL databases (MSSQL, GCP BigQuery)\n",
      "• Experience working with message stream systems (Pub/Sub -Kafka, RabbitMQ)\n",
      "• Experience working in agile environment (Scrum, daily standups etc)\n",
      "• Experience of delivering and supporting a large-scale production system\n",
      "• Experience with being a core contributor to a software project: understanding domain and business requirements, being responsible for critical parts of the application.\n",
      "• Experience working with logging and application monitoring stack: Splunk, Dynatrace,Grafana\n",
      "• Good communication skills, working in multi-team project.\n",
      "\n",
      "Minimum Qualifications...\n",
      "\n",
      "Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\n",
      "\n",
      "Option 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area.Option 2: 3 years’ experience in software engineering or related area.\n",
      "\n",
      "Preferred Qualifications...\n",
      "\n",
      "Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n",
      "\n",
      "Certification in Security+, Network+, GISF, or GSEC\n",
      "\n",
      "Primary Location...\n",
      "608 SW 8TH ST, BENTONVILLE, AR 72712-6207, United States of America\n",
      "_______________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the results of a search, as a regular function\n",
    "print(google_job_search(\"Software Engineer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_______________________________________________\\nJob Title: (USA) Software Engineer II\\nCompany Name: Walmart\\nLocation:   Bentonville, AR   \\nDescription: Position Summary...\\n\\nWhat you'll do...\\n\\nWhat you'll do...\\n\\nIt’s exciting time to join our Walmart journey. We are seeking a Software Engineer III to support the Finance Technology. \\u202f\\n\\nAbout the Team\\n\\nAs a part of Walmart Finance Technology – Finance Data Factory (FDF), we build industry defining Data platform/workflows that process large quality of general ledger data and applications that run on data platform for visualization also, Machine Learning and statistical modeling that enable transparency, governance, and automation. The goals include improved Business partner user experience; standardizing the core and utilizing reporting/predictive analytics to uncover insights faster.\\n\\nYou will be in the unique position to be of service to associates as a member of this organization supporting all segments of Walmart Finance. If you are the type of person who feels a personal stake in everything that you work on, has a strong sense of ownership, has a love for financial data, enjoys solving complex problems, has a passion for privacy, knows how to foster strong relationships and build trust, and works for the success of the product - then this role could be for you. The ideal candidate will be a driver for any given workstream within the program, working closely with the engineering and business teams to take an idea thru implementation and stabilization.\\n\\nAlso, you will be positioned to work on building re-usable frameworks for centralized data flow monitoring & Data Quality like impact-based alerting, orchestrate with multiple systems in the landscape to provide end-to-end visibility and connectivity between the systems to achieve a business goal. Identifies data gaps upfront. Provides visibility into data correctness, completeness, accuracy for downstream systems. Enabling data transparency, insights hence help kick off the data remediation process in upstream systems.\\n\\nYou’ll really wow us if…\\n• You are a driver, takes responsibility to ensure timely delivery.\\n• You are passionate, driven and humble in your approach.\\n• You’re excited about solving challenges.\\n• You’re team-centric in spirit and in execution.\\n• You’re leading and participating in medium- to large-scale, complex, cross-functional projects by reviewing project requirements, translating requirements into technical solutions, gathering requested information (for example, design documents, product requirements, wire frames).\\n• You’re writing and developing code; conducting unit testing, communicating status and issues to team members and stakeholders, collaborating with project team and cross functional teams.\\n\\nYou’ll make an impact by…\\n• Effectively translating requirements into project parameters while working with agility.\\n• Helping cross-functional teams to solve for business problems and develop solutions that enable us to redefine a “best-in-class” customer experience.\\n• Encouraging the project teams that you oversee to work collaboratively and to aim for insight-driven outcomes.\\n\\nResponsibilities & Qualifications…\\n• Experience in Technical Solutions Architecture and design leadership.\\n• Experience using Javascript, HTML/CSS, ReactJs or next.js\\n• Strong Java, Spring framework, Kafka, SQL and cloud experience such as Azure.\\n• Strong experience in RESTful Microservices\\n• Container technologies such as Docker on Kubernetes\\n• Strong API design, development, and management\\n• Experience with cloud native technology, CI/CD (KITT)\\n• Experience with third-party libraries and APIs\\n• Clear Communication, including the ability to create functional charts.\\n• Ability to multitask between several different requirements and features concurrently.\\n• Superior analytical skills with a good problem-solving attitude.\\n• Ability to perform in a team environment.\\n• Being an independent thinker and problem solver\\n• Being able to understand UI tech stack, needs and limitations.\\n• Strong sense of urgency\\n\\nExperience\\n• 3 to 4 years of software development experience\\n• Professional frontend development experience using Javascript, HTML/CSS, ReactJs or next.js\\n• Strong experience with UI tech stack using React JS, React native\\n• Experience with UI testing frameworks like Jest\\n• Software development (Java or Python, Pysprak is preferable)\\n• Solid skills in java stack (Spring, Maven, Hibernate)\\n• Solid experience with REST APIs\\n• Strong experience within the Cloud Services using Azure or Google GCP\\n• Experience with Spark Engine (Databrick or DataProc)\\n• Experience working with building Data Engineering Pipelines\\n• Experience using source control systems (git)\\n• Experience with working with CI/CD (Jenkins/Travis)\\n• Experience with working with cloud deployments (scaling, resiliency, load balancing etc)\\n• Experience with SQL and NoSQL databases (MSSQL, GCP BigQuery)\\n• Experience working with message stream systems (Pub/Sub -Kafka, RabbitMQ)\\n• Experience working in agile environment (Scrum, daily standups etc)\\n• Experience of delivering and supporting a large-scale production system\\n• Experience with being a core contributor to a software project: understanding domain and business requirements, being responsible for critical parts of the application.\\n• Experience working with logging and application monitoring stack: Splunk, Dynatrace,Grafana\\n• Good communication skills, working in multi-team project.\\n\\nMinimum Qualifications...\\n\\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\\n\\nOption 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area.Option 2: 3 years’ experience in software engineering or related area.\\n\\nPreferred Qualifications...\\n\\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\\n\\nCertification in Security+, Network+, GISF, or GSEC\\n\\nPrimary Location...\\n608 SW 8TH ST, BENTONVILLE, AR 72712-6207, United States of America\\n_______________________________________________\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function as a tool\n",
    "google_job_search.run(\"Software Engineer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Wikipedia Search](https://python.langchain.com/docs/integrations/tools/wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"wiki_search\")\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This function uses the WikipediaAPIWrapper to search for information on Wikipedia.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The search term to use in the query.\n",
    "\n",
    "    Returns:\n",
    "    str: The search results from Wikipedia.\n",
    "    \"\"\"\n",
    "    # create an instance of the WikipediaAPIWrapper\n",
    "    wikisearch = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "    # Perform the search query\n",
    "    results = wikisearch.run(query)\n",
    "\n",
    "    # return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: The Body Keeps the Score\n",
      "Summary: The Body Keeps the Score: Brain, Mind, and Body in the Healing of Trauma is a 2014 book by Bessel van der Kolk about the effects of psychological trauma, also known as traumatic stress. The book describes van der Kolk's research and experiences on how individuals are affected by traumatic stress, and its effects on the mind and body. It is based on his 1994 Harvard Review of Psychiatry article \"The body keeps the score: memory and the evolving psychobiology of posttraumatic stress\".The Body Keeps the Score has been published in 36 languages. As of July 2021 the book had spent more than 141 weeks on the New York Times Bestseller List for nonfiction, with 27 of those weeks spent in the No. 1 position.\n",
      "\n",
      "Page: Bessel van der Kolk\n",
      "Summary: Bessel van der Kolk (born 1943) is a psychiatrist, author, researcher and educator based in Boston, United States. Since the 1970s his research has been in the area of post-traumatic stress. He is the author of The New York Times best seller, The Body Keeps the Score. \n",
      "Van der Kolk formerly served as president of the International Society for Traumatic Stress Studies and is a former co-director of the National Child Traumatic Stress Network. He is a professor of psychiatry at Boston University School of Medicine and president of the Trauma Research Foundation in Brookline, Massachusetts, which he established after being fired from the Brookline Trauma Center for \"creating a hostile work environment,\" in which he allegedly made employees feel \"denigrated and uncomfortable.\"Van der Kolk has published over 150 peer-reviewed scientific articles and four books.\n",
      "\n",
      "Page: Body memory\n",
      "Summary: Body memory (BM) is a hypothesis that the body itself is capable of storing memories, as opposed to only the brain. While experiments have demonstrated the possibility of cellular memory there are currently no known means by which tissues other than the brain would be capable of storing memories.Modern usage of BM tends to frame it exclusively in the context of traumatic memory and ways in which the body responds to recall of a memory. In this regard, it has become relevant in treatment for PTSD.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test create_search_tool function\n",
    "print(wiki_search(\"The Body Keeps the Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: The Body Keeps the Score\\nSummary: The Body Keeps the Score: Brain, Mind, and Body in the Healing of Trauma is a 2014 book by Bessel van der Kolk about the effects of psychological trauma, also known as traumatic stress. The book describes van der Kolk\\'s research and experiences on how individuals are affected by traumatic stress, and its effects on the mind and body. It is based on his 1994 Harvard Review of Psychiatry article \"The body keeps the score: memory and the evolving psychobiology of posttraumatic stress\".The Body Keeps the Score has been published in 36 languages. As of July 2021 the book had spent more than 141 weeks on the New York Times Bestseller List for nonfiction, with 27 of those weeks spent in the No. 1 position.\\n\\nPage: Bessel van der Kolk\\nSummary: Bessel van der Kolk (born 1943) is a psychiatrist, author, researcher and educator based in Boston, United States. Since the 1970s his research has been in the area of post-traumatic stress. He is the author of The New York Times best seller, The Body Keeps the Score. \\nVan der Kolk formerly served as president of the International Society for Traumatic Stress Studies and is a former co-director of the National Child Traumatic Stress Network. He is a professor of psychiatry at Boston University School of Medicine and president of the Trauma Research Foundation in Brookline, Massachusetts, which he established after being fired from the Brookline Trauma Center for \"creating a hostile work environment,\" in which he allegedly made employees feel \"denigrated and uncomfortable.\"Van der Kolk has published over 150 peer-reviewed scientific articles and four books.\\n\\nPage: Body memory\\nSummary: Body memory (BM) is a hypothesis that the body itself is capable of storing memories, as opposed to only the brain. While experiments have demonstrated the possibility of cellular memory there are currently no known means by which tissues other than the brain would be capable of storing memories.Modern usage of BM tends to frame it exclusively in the context of traumatic memory and ways in which the body responds to recall of a memory. In this regard, it has become relevant in treatment for PTSD.\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function as a tool\n",
    "wiki_search.run(\"The Body Keeps the Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Agent using [HuggingFaceHub](https://python.langchain.com/docs/integrations/chat/huggingface#huggingfacehub \"Learn more\")\n",
    "\n",
    "Works with *HuggingFaceTextGenInference*, *HuggingFaceEndpoint*, and *HuggingFaceHub* LLMs.\n",
    "\n",
    "Upon instantiating this class, the model_id is resolved from the url provided to the LLM, and the appropriate tokenizer is loaded from the HuggingFace Hub.\n",
    "\n",
    "See the [Python API Documentation for LangChain](https://api.python.langchain.com/en/stable/chat_models/langchain_community.chat_models.huggingface.ChatHuggingFace.html?highlight=chathuggingface#langchain-community-chat-models-huggingface-chathuggingface \"Learn more\") for more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dae\\.vscode\\Software\\Build-AI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING! repo_id is not default parameter.\n",
      "                    repo_id was transferred to model_kwargs.\n",
      "                    Please confirm that repo_id is what you intended.\n",
      "WARNING! task is not default parameter.\n",
      "                    task was transferred to model_kwargs.\n",
      "                    Please confirm that task is what you intended.\n",
      "WARNING! huggingfacehub_api_token is not default parameter.\n",
      "                    huggingfacehub_api_token was transferred to model_kwargs.\n",
      "                    Please confirm that huggingfacehub_api_token is what you intended.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# Instantiate the HuggingFaceHub LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 4096,\n",
    "        \"top_k\": 35,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.05,\n",
    "    },\n",
    "    huggingfacehub_api_token=\"\",\n",
    "    )\n",
    "\n",
    "# Instantiate `ChatHuggingFace` to apply chat templates\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LangChain Chat templates via `ChatHuggingFace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"I can choose to use different tools to accomplish a variety of tasks.\"),\n",
    "    HumanMessage(content=\"I have a question I need help answering:\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nI can choose to use different tools to accomplish a variety of tasks.</s>\\n<|user|>\\nI have a question I need help answering:</s>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what the chat messages look like before they are formatted for the LLM call.\n",
    "chat_model._to_chat_prompt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "I can choose to use different tools to accomplish a variety of tasks.</s>\n",
      "<|user|>\n",
      "I have a question I need help answering:</s>\n",
      "<|assistant|>\n",
      "Please provide me with the question you need help answering, and I will do my best to provide a clear and concise response. Alternatively, you can specify the topic or context of the question to help me understand it better. Thank you!\n"
     ]
    }
   ],
   "source": [
    "# Call the model\n",
    "res = chat_model.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "The above section setting up the HuggingFace LLM broke somewhere around patch \"0.1.0\" of LangChain. F**k it, we'll use ChatOpenAI, since it seems to be the only one that works consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.3,\n",
    "    openai_api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Agent\n",
    "\n",
    "**What's an agent?**: An Agent in the context of LLMs and LangChain is a software entity that utilizes a Language Model (LLM) to perform tasks and interact with users. It acts as an intermediary between the user and the LLM, determining which actions to take and in what order. Agents can call external tools, utilize memory, and employ various strategies to achieve their goals, making them powerful problem-solving entities in the realm of natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, load_tools\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import (\n",
    "    ReActJsonSingleInputOutputParser,\n",
    ")\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=HuggingFaceHub(client=<InferenceClient(model='HuggingFaceH4/zephyr-7b-beta', timeout=None)>, repo_id='HuggingFaceH4/zephyr-7b-beta', task='text-generation', model_kwargs={'max_new_tokens': 4096, 'top_k': 35, 'temperature': 0.1, 'repetition_penalty': 1.05, 'repo_id': 'HuggingFaceH4/zephyr-7b-beta', 'task': 'text-generation', 'huggingfacehub_api_token': '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'}, huggingfacehub_api_token='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')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=HuggingFaceHub(client=<InferenceClient(model='HuggingFaceH4/zephyr-7b-beta', timeout=None)>, repo_id='HuggingFaceH4/zephyr-7b-beta', task='text-generation', model_kwargs={'max_new_tokens': 4096, 'top_k': 35, 'temperature': 0.1, 'repetition_penalty': 1.05, 'repo_id': 'HuggingFaceH4/zephyr-7b-beta', 'task': 'text-generation', 'huggingfacehub_api_token': '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'}, huggingfacehub_api_token='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')))>),\n",
       " StructuredTool(name='arxiv_search', description='arxiv_search(query: str) -> str - This function uses the ArxivAPIWrapper to search for scientific papers on Arxiv.\\n\\n    Parameters:\\n    query (str): The search term to use in the query.\\n\\n    Returns:\\n    str: The search results from Arxiv.', args_schema=<class 'pydantic.v1.main.arxiv_searchSchemaSchema'>, func=<function arxiv_search at 0x000001D09E456DE0>),\n",
       " StructuredTool(name='google_job_search', description='google_job_search(query: str) -> str - This function uses the GoogleJobsAPIWrapper to search for jobs on Google Jobs.\\n\\n    Parameters:\\n    query (str): The search term to use in the query.\\n\\n    Returns:\\n    str: The search results from Google Jobs.', args_schema=<class 'pydantic.v1.main.google_job_searchSchemaSchema'>, func=<function google_job_search at 0x000001D09B7C5120>),\n",
       " StructuredTool(name='wiki_search', description='wiki_search(query: str) -> str - This function uses the WikipediaAPIWrapper to search for information on Wikipedia.\\n\\n    Parameters:\\n    query (str): The search term to use in the query.\\n\\n    Returns:\\n    str: The search results from Wikipedia.', args_schema=<class 'pydantic.v1.main.wiki_searchSchemaSchema'>, func=<function wiki_search at 0x000001D0BD3A7BA0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the tools\n",
    "# `load_tools` doesn't support custom tools, so we'll initialize it as an empty list\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# and now we'll append our custom tools\n",
    "tools = tools + [arxiv_search, google_job_search, wiki_search]\n",
    "\n",
    "# Inspect the tools\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup ReAct style prompt\n",
    "prompt = hub.pull(\"hwchase17/react-json\")\n",
    "prompt = prompt.partial(\n",
    "    tools=render_text_description(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "# define the agent\n",
    "chat_model_with_stop = chat_model.bind(stop=[\"\\nObservation\"])\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | chat_model_with_stop\n",
    "    | ReActJsonSingleInputOutputParser()\n",
    ")\n",
    "\n",
    "# instantiate AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is OHSU? How old is it in years? At what address can I find it?\n",
      "\n",
      "Thought: OHSU could be an organization or institution. I should start by searching for information about OHSU to understand what it is and its age. Once I have that information, I can look for its address.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wiki_search\",\n",
      "  \"action_input\": \"OHSU\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mPage: Oregon Health & Science University\n",
      "Summary: Oregon Health & Science University (OHSU) is a\n",
      "public research university focusing primarily on health sciences with a main campus, including two hospitals, in Portland, Oregon. The institution was founded in 1887 as the University of Oregon Medical Department and later became the University of Oregon Medical School. In 1974, the campus became an independent, self-governed institution called the University of Oregon Health Sciences Center, combining state dentistry, medicine, nursing, and public health programs into a single center. It was renamed Oregon Health Sciences University in 1981 and took its current name in 2001, as part of a merger with the Oregon Graduate Institute (OGI), in Hillsboro. The university has several partnership programs including a joint PharmD Pharmacy program with Oregon State University in Corvallis.\n",
      "The university's programs are highly ranked nationally, with the School of Medicine ranking in the top 5 for primary care and family medicine residency ranking #1 by U.S. News & World Report, as well as the ophthalmology residency under Casey Eye Institute ranking in the top 10 by Ophthalmology Times in 2020. It is designated as a \"Special Focus - Research Institution\" according to the Carnegie Classification.\n",
      "\n",
      "Page: Portland Aerial Tram\n",
      "Summary: The Portland Aerial Tram or OHSU Tram is an aerial tramway in Portland, Oregon, that connects the city's South Waterfront district and the main Oregon Health & Science University (OHSU) campus, located in the Marquam Hill neighborhood. It is one of only two commuter aerial tramways in the United States, the other being New York City's Roosevelt Island Tramway.  The tram travels a horizontal distance of 3,300 feet (1,000 m) and a vertical distance of 500 feet (152 m) in a ride that lasts three minutes.The tram was jointly funded by OHSU, the City of Portland, and by South Waterfront property owners, with most of the funding coming from OHSU. It is owned by the city and operated by OHSU. While most passengers are affiliated with OHSU, it is open to the public and operated as part of Portland's public transportation network that includes the Portland Streetcar, MAX Light Rail, and TriMet buses. After opening in December 2006, the tram carried its one millionth passenger on October 17, 2007 and its ten millionth rider on January 8, 2014. A round-trip ticket costs $8 but is free for OHSU patients and certain visitors; OHSU employees and students ride free by showing their ID badges.The tram cost $57 million to build—a nearly fourfold increase over initial cost estimates, which was one of several sources of controversy concerning the project.\n",
      "\n",
      "Page: Oregon Health & Science University Hospital\n",
      "Summary: Oregon Health & Science University Hospital (OHSU Hospital) is a 576-bed teaching hospital, biomedical research facility, and Level I trauma center located on the campus of Oregon Health & Science University (OHSU) in Portland in the U.S. state of Oregon. OHSU hospital has consistently been ranked by the U.S. News & World Report as the #1 hospital in the Portland metro regional area and is frequently ranked nationally in multiple medical specialties.\n",
      "Located on OHSU's Marquam Hill campus south of Downtown Portland, the hospital is adjacent to Doernbecher Children's Hospital and a Shriners Hospital for Children. OHSU Hospital is one of only two Level I trauma centers in Oregon.\u001b[0m\u001b[32;1m\u001b[1;3mThought: Based on the information from the Wikipedia search, OHSU stands for Oregon Health & Science University. It was founded in 1887 as the University of Oregon Medical Department, making it 134 years old. The address of the main campus is in Portland, Oregon.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wiki_search\",\n",
      "  \"action_input\": \"Oregon Health & Science University address\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mPage: Western University of Health Sciences\n",
      "Summary: Western University of Health Sciences (WesternU) is a private medical university in Pomona, California. With an enrollment of 3,724 students (2022–23), WesternU offers more than twenty academic programs in multiple colleges. It also operates an additional campus in Lebanon, Oregon.\n",
      "Under the banner of WesternU Health, the university operates a variety of patient care facilities in California and Oregon. The Pomona and Lebanon (Oregon) campuses both include a medical center, dental center, eye care institute, pharmacy, and travel health center. WesternU-Pomona also is home to the Pet Health Center, which provides veterinary services. Dental services are offered at the Rancho Mirage campus, while a Los Angeles campus provides optometry services.\n",
      "Several nonprofit organizations are based at the WesternU Pomona campus, including the Harris Family Center for Disability and Health Policy. The Center for Oral Health, moved from the Bay area to the WesternU Pomona campus in 2012. In 2015, the Southern California Medical Museum moved to the Pomona campus.\n",
      "Founded in 1977, the first program at WesternU was its medical school, the College of Osteopathic Medicine of the Pacific. In 2003, the College of Veterinary Medicine opened, and in 2009 the colleges of dental medicine, optometry, and podiatric medicine opened. In 2011, the university opened an additional campus in Lebanon, Oregon, the College of Osteopathic Medicine of the Pacific - Northwest (COMP-Northwest). In 2015, the university's founding president, Philip Pumerantz, retired.\n",
      "All of the programs at WesternU have professional accreditation and the university is accredited by the Western Association of Schools and Colleges.\n",
      "\n",
      "Page: University of Oregon\n",
      "Summary: The University of Oregon (UO, U of O or Oregon) is a public research university in Eugene, Oregon. Founded in 1876, the university also has two Portland locations, and manages a marine station, called the Oregon Institute of Marine Biology, in Charleston; and an observatory, called Pine Mountain Observatory, in Central Oregon.\n",
      "The University of Oregon is organized into nine colleges and schools and offers 316 undergraduate and graduate degree programs. Most academic programs follow the 10 week Quarter System. The university is classified among \"R1: Doctoral Universities – Very high research activity\" and is a member of the Association of American Universities. Since July 2014, UO has been governed by its own board of trustees.\n",
      "UO's 295-acre campus is situated along the Willamette River.\n",
      "UO student athletes compete as the Ducks and are part of the Pac-12 Conference in the National Collegiate Athletic Association (NCAA). With eighteen varsity teams, the Oregon Ducks are best known for their football team and track and field program. These two teams are even incorporated into the design of the school's \"O\" logo. In the summer of 2022, UO hosted the 2022 World Athletics Championships. It was the first time the event was held in the United States. UO's colors are green and yellow.The university has a long and complex relationship with Nike, Inc., and the firm's co-founder Phil Knight. As a consequence of state higher-education disinvestment starting in the 1990s, UO has embraced a \"University of Nike\" image. Fueled by large investments in athletic infrastructure, this trend has accelerated in recent years. Knight, an alumnus, has advocated for both athletic prominence and increased privatisation of the university, and has donated over $1 billion to UO since the late-1980s, much of it going towards athletics. The school's \"O\" logo was designed by Nike in 1998 and sports facility projects on campus typically involve both Knight and Nike.\n",
      "\n",
      "Page: Southern Oregon University\n",
      "Summary: Southern Oregon University (SOU) is a public university in Ashland, Oregon. It was founded in 1872 as the Ashland Academy, has been in its current location since 1926, and was known by nine other names \u001b[0m\u001b[32;1m\u001b[1;3mBased on the information from the Wikipedia search, OHSU stands for Oregon Health & Science University. It was founded in 1887 as the University of Oregon Medical Department, making it 134 years old. The address of the main campus is in Portland, Oregon.\n",
      "\n",
      "Final Answer: Oregon Health & Science University (OHSU) is 134 years old and its main campus is located in Portland, Oregon.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is OHSU? How old is it in years? At what address can I find it?',\n",
       " 'output': 'Oregon Health & Science University (OHSU) is 134 years old and its main campus is located in Portland, Oregon.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is OHSU? How old is it in years? At what address can I find it?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Trace\n",
    "The latest trace was lightning fast. It only took a single wiki search to find the answer.\n",
    "\n",
    "You can check out the chain's trace [here](https://smith.langchain.com/public/3f7cd76d-b279-4e6b-a6ec-0efe916ab4ed/r \"AgentExecutor: Full LangSmith trace\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
